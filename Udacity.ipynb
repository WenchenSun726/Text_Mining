{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling - Udacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: future in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.31.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.10)\n",
      "Requirement already satisfied: numexpr in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.6.5)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.14.3)\n",
      "Requirement already satisfied: pytest in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (3.5.1)\n",
      "Requirement already satisfied: funcy in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.11)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis) (1.0)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.5.3)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (39.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (18.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (4.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.3.9)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2.7.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "!{sys.executable} -m pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html.parser\n",
      "Requirement already satisfied: ply in c:\\anaconda3\\lib\\site-packages (from html.parser) (3.11)\n",
      "Installing collected packages: html.parser\n",
      "Successfully installed html.parser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pattern3 in c:\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: simplejson in c:\\anaconda3\\lib\\site-packages (from pattern3) (3.16.0)\n",
      "Requirement already satisfied: pdfminer3k in c:\\anaconda3\\lib\\site-packages (from pattern3) (1.3.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\anaconda3\\lib\\site-packages (from pattern3) (4.6.0)\n",
      "Requirement already satisfied: feedparser in c:\\anaconda3\\lib\\site-packages (from pattern3) (5.2.1)\n",
      "Requirement already satisfied: docx in c:\\anaconda3\\lib\\site-packages (from pattern3) (0.2.4)\n",
      "Requirement already satisfied: cherrypy in c:\\anaconda3\\lib\\site-packages (from pattern3) (18.1.1)\n",
      "Requirement already satisfied: pdfminer.six in c:\\anaconda3\\lib\\site-packages (from pattern3) (20181108)\n",
      "Requirement already satisfied: ply>=3.4 in c:\\anaconda3\\lib\\site-packages (from pdfminer3k->pattern3) (3.11)\n",
      "Requirement already satisfied: pytest>=2.0 in c:\\anaconda3\\lib\\site-packages (from pdfminer3k->pattern3) (3.5.1)\n",
      "Requirement already satisfied: lxml in c:\\anaconda3\\lib\\site-packages (from docx->pattern3) (4.2.1)\n",
      "Requirement already satisfied: Pillow>=2.0 in c:\\anaconda3\\lib\\site-packages (from docx->pattern3) (5.1.0)\n",
      "Requirement already satisfied: portend>=2.1.1 in c:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (2.3)\n",
      "Requirement already satisfied: more-itertools in c:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (4.1.0)\n",
      "Requirement already satisfied: zc.lockfile in c:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (1.4)\n",
      "Requirement already satisfied: pywin32; sys_platform == \"win32\" in c:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (223)\n",
      "Requirement already satisfied: cheroot>=6.2.4 in c:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (6.5.4)\n",
      "Requirement already satisfied: sortedcontainers in c:\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (1.5.10)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (1.11.0)\n",
      "Requirement already satisfied: pycryptodome in c:\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (3.8.1)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (1.5.3)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (39.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (18.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in c:\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (0.3.9)\n",
      "Requirement already satisfied: tempora>=1.8 in c:\\anaconda3\\lib\\site-packages (from portend>=2.1.1->cherrypy->pattern3) (1.14)\n",
      "Requirement already satisfied: backports.functools-lru-cache in c:\\anaconda3\\lib\\site-packages (from cheroot>=6.2.4->cherrypy->pattern3) (1.5)\n",
      "Requirement already satisfied: jaraco.functools>=1.20 in c:\\anaconda3\\lib\\site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2.0)\n",
      "Requirement already satisfied: pytz in c:\\anaconda3\\lib\\site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2018.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.14.3)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.10)\n",
      "Requirement already satisfied: future in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: numexpr in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.6.5)\n",
      "Requirement already satisfied: pytest in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (3.5.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.31.1)\n",
      "Requirement already satisfied: funcy in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.11)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.23.0)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis) (1.0)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.5.3)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (39.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (18.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (4.1.0)\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.3.9)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2.7.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Original:   [\"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\", \"<p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\"] \n",
      "\n",
      "Processed:  ['circus dog plisse skirt jump python large foot long', 'circus dog plisse skirt jump python large foot long']\n"
     ]
    }
   ],
   "source": [
    "path = '--'\n",
    "%run ./Text_Normalization_Function.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+\"Udacity_txt.txt\", delimiter = \"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove http, and @ and username\n",
    "for index, row in df.iterrows():\n",
    "    row[0] = str(row[0]).split(\" \")\n",
    "    for i in range(len(row[0])):\n",
    "        row[0][i] = \"\".join([word for word in row[0][i].split()\n",
    "                            if \"http\" not in word and \"@\" not in word and \"<\" not in word])\n",
    "    row[0] = \",\".join(row[0])\n",
    "    row[0] = str(row[0]).replace(\",\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** LDA Topic Model ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000s</th>\n",
       "      <th>07psyrntwf</th>\n",
       "      <th>08rnt87bvt</th>\n",
       "      <th>0biqvjgaqm</th>\n",
       "      <th>0h2plto95e</th>\n",
       "      <th>0rduy8mluy</th>\n",
       "      <th>0rrogcixwm</th>\n",
       "      <th>0sghq6jdqn</th>\n",
       "      <th>100daysofcode</th>\n",
       "      <th>100daysofmlcode</th>\n",
       "      <th>...</th>\n",
       "      <th>zicgwx6krw</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zmqojpcpis</th>\n",
       "      <th>znhlyvqxgf</th>\n",
       "      <th>znsrym6qvm</th>\n",
       "      <th>zop6oyyidj</th>\n",
       "      <th>zpjediouqc</th>\n",
       "      <th>zqv1itixrm</th>\n",
       "      <th>zsgegskg0a</th>\n",
       "      <th>zvjekku9vy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000s  07psyrntwf  08rnt87bvt  0biqvjgaqm  0h2plto95e  0rduy8mluy  \\\n",
       "0     0           0           0           0           0           0   \n",
       "1     0           0           0           0           0           0   \n",
       "2     0           0           0           0           0           0   \n",
       "3     0           0           0           0           0           0   \n",
       "4     0           0           0           0           0           0   \n",
       "\n",
       "   0rrogcixwm  0sghq6jdqn  100daysofcode  100daysofmlcode     ...      \\\n",
       "0           0           0              0                0     ...       \n",
       "1           0           0              0                0     ...       \n",
       "2           0           0              0                0     ...       \n",
       "3           0           0              0                0     ...       \n",
       "4           0           0              0                0     ...       \n",
       "\n",
       "   zicgwx6krw  zillow  zmqojpcpis  znhlyvqxgf  znsrym6qvm  zop6oyyidj  \\\n",
       "0           0       0           0           0           0           0   \n",
       "1           0       0           0           0           0           0   \n",
       "2           0       0           0           0           0           0   \n",
       "3           0       0           0           0           0           0   \n",
       "4           0       0           0           0           0           0   \n",
       "\n",
       "   zpjediouqc  zqv1itixrm  zsgegskg0a  zvjekku9vy  \n",
       "0           0           0           0           0  \n",
       "1           0           0           0           0  \n",
       "2           0           0           0           0  \n",
       "3           0           0           0           0  \n",
       "4           0           0           0           0  \n",
       "\n",
       "[5 rows x 2219 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_udacity = normalize_corpus(df[1])\n",
    "bow_vectorizer_udacity = CountVectorizer()\n",
    "bow_udacity_corpus = bow_vectorizer_udacity.fit_transform(normalized_udacity)\n",
    "bow_feature_names_udacity = bow_vectorizer_udacity.get_feature_names()\n",
    "bow_table = pd.DataFrame(data = bow_udacity_corpus.todense(), columns = bow_feature_names_udacity)\n",
    "bow_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# set up the model \n",
    "no_topics = 3\n",
    "lda_udacity_corpus = LatentDirichletAllocation(n_components=no_topics, \n",
    "                                           doc_topic_prior = 0.3,\n",
    "                                           topic_word_prior = 0.2).fit(bow_udacity_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic_0</th>\n",
       "      <td>learn</td>\n",
       "      <td>google</td>\n",
       "      <td>free</td>\n",
       "      <td>computer</td>\n",
       "      <td>job</td>\n",
       "      <td>science</td>\n",
       "      <td>want</td>\n",
       "      <td>web</td>\n",
       "      <td>today</td>\n",
       "      <td>build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_1</th>\n",
       "      <td>notebook</td>\n",
       "      <td>idea</td>\n",
       "      <td>video</td>\n",
       "      <td>graffiti</td>\n",
       "      <td>live</td>\n",
       "      <td>top</td>\n",
       "      <td>great</td>\n",
       "      <td>sound</td>\n",
       "      <td>projectjupyter</td>\n",
       "      <td>annotation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_2</th>\n",
       "      <td>nanodegree</td>\n",
       "      <td>data</td>\n",
       "      <td>day</td>\n",
       "      <td>learning</td>\n",
       "      <td>100daysofcode</td>\n",
       "      <td>course</td>\n",
       "      <td>program</td>\n",
       "      <td>new</td>\n",
       "      <td>machine</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word_0  word_1 word_2    word_3         word_4   word_5   word_6  \\\n",
       "Topic_0       learn  google   free  computer            job  science     want   \n",
       "Topic_1    notebook    idea  video  graffiti           live      top    great   \n",
       "Topic_2  nanodegree    data    day  learning  100daysofcode   course  program   \n",
       "\n",
       "        word_7          word_8      word_9  \n",
       "Topic_0    web           today       build  \n",
       "Topic_1  sound  projectjupyter  annotation  \n",
       "Topic_2    new         machine      amazon  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "def get_topic_words(vectorizer, lda_model, n_words):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_words = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_word_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_words.append(keywords.take(top_word_locs).tolist())\n",
    "    return topic_words\n",
    "\n",
    "topic_words = get_topic_words(vectorizer = bow_vectorizer_udacity, \n",
    "                              lda_model = lda_udacity_corpus, \n",
    "                              n_words = no_top_words)\n",
    "pd.DataFrame(topic_words, \n",
    "             columns = [\"word_\" + str(i) for i in range(no_top_words)],\n",
    "             index = [\"Topic_\" + str(i) for i in range(len(topic_words))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000s</th>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07psyrntwf</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08rnt87bvt</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0biqvjgaqm</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0h2plto95e</th>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0rduy8mluy</th>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0rrogcixwm</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0sghq6jdqn</th>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100daysofcode</th>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.017628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100daysofmlcode</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Topic_0   Topic_1   Topic_2\n",
       "000s             0.000572  0.000073  0.000043\n",
       "07psyrntwf       0.000061  0.000392  0.000042\n",
       "08rnt87bvt       0.000061  0.000418  0.000044\n",
       "0biqvjgaqm       0.000061  0.002010  0.000042\n",
       "0h2plto95e       0.000365  0.000073  0.000043\n",
       "0rduy8mluy       0.001674  0.000073  0.000049\n",
       "0rrogcixwm       0.000061  0.000075  0.000234\n",
       "0sghq6jdqn       0.000062  0.000352  0.000042\n",
       "100daysofcode    0.000063  0.000074  0.017628\n",
       "100daysofmlcode  0.000061  0.000797  0.000043"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weights = lda_udacity_corpus.components_ / lda_udacity_corpus.components_.sum(axis=1)[:, np.newaxis]\n",
    "word_weights_df = pd.DataFrame(word_weights.T, \n",
    "                               index = bow_feature_names_udacity, \n",
    "                               columns = [\"Topic_\" + str(i) for i in range(no_topics)])\n",
    "word_weights_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn</th>\n",
       "      <td>0.030244</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>0.012395</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>0.011908</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>0.011870</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.002350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>0.010851</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>0.010069</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.007410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Topic_0   Topic_1   Topic_2\n",
       "learn     0.030244  0.008100  0.000049\n",
       "google    0.013545  0.000133  0.000197\n",
       "free      0.012395  0.000143  0.000423\n",
       "computer  0.011908  0.000076  0.000043\n",
       "job       0.011870  0.000082  0.002350\n",
       "science   0.010851  0.000077  0.000045\n",
       "want      0.010233  0.000091  0.000043\n",
       "web       0.010069  0.000074  0.004110\n",
       "today     0.009659  0.000074  0.007410\n",
       "build     0.008008  0.002793  0.000052"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc_0</th>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_1</th>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_2</th>\n",
       "      <td>0.1462</td>\n",
       "      <td>0.8259</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_3</th>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic_0  Topic_1  Topic_2  dominant_topic\n",
       "Doc_0   0.1581   0.6839   0.1580               1\n",
       "Doc_1   0.9237   0.0384   0.0380               0\n",
       "Doc_2   0.1462   0.8259   0.0279               1\n",
       "Doc_3   0.0280   0.0278   0.9442               2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find out the dominant topic\n",
    "lda_udacity_output = lda_udacity_corpus.transform(bow_udacity_corpus)\n",
    "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_udacity))]\n",
    "topic_names = [\"Topic_\" + str(i) for i in range(no_topics)]\n",
    "df_document_topic = pd.DataFrame(np.round(lda_udacity_output, 4), columns=topic_names, index=doc_names)\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "df_document_topic[0:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2301621963515820242389832568\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2301621963515820242389832568_data = {\"mdsDat\": {\"x\": [-372.1424560546875, -437.7695617675781, -620.1272583007812], \"y\": [-195.24327087402344, -443.70355224609375, -262.63836669921875], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [44.25185319549328, 30.176353573945676, 25.571793230561045]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [73.0, 108.0, 106.0, 86.0, 84.0, 46.0, 78.0, 74.0, 42.0, 71.0, 41.0, 40.0, 40.0, 36.0, 36.0, 36.0, 35.0, 73.0, 57.0, 40.0, 34.0, 29.0, 37.0, 31.0, 29.0, 43.0, 55.0, 41.0, 22.0, 44.0, 86.01032118142862, 74.22592179848753, 84.34701529448775, 107.70597264351831, 71.25849075891311, 78.3678977275698, 56.83825136700943, 41.616709468693, 43.1430883127082, 37.91035093373357, 32.26265799033359, 32.262717156998384, 29.174830094170318, 27.054650006248448, 24.499700567415157, 24.406852048138305, 23.666218858996256, 22.08623768770335, 19.835232199434287, 19.067458777252142, 19.066665608502834, 19.06693267259596, 19.066127303394712, 17.31132597718598, 41.047710552905286, 16.660383512588464, 15.878881669593492, 15.260357429779305, 15.043385331774019, 14.802572797821952, 70.49999122143241, 22.437753758593004, 16.20719513450177, 71.802011220343, 42.758713407568656, 21.550448308254186, 35.291923229735445, 31.970087761169346, 37.194793521315944, 27.723772815122224, 31.004837898707716, 31.200499788291374, 30.11623900436032, 34.19244251248935, 31.155727201242158, 29.381599582276174, 22.14307472873702, 22.174726538890752, 20.457294885306034, 18.874872708596296, 18.74006745142019, 18.05296321249639, 16.909360131596173, 16.466589375578565, 15.708619659454174, 15.406196863096485, 15.145683579037588, 14.78640184985046, 14.883137195908645, 13.967035682426106, 13.843788401587418, 13.245458235516475, 14.50899964194778, 12.710275841180188, 12.498323486517222, 12.259115077946035, 12.258844598947341, 12.259258909541746, 38.8901164272401, 12.046551959174536, 11.837542224753156, 11.344446281883856, 11.344263629129562, 35.58918776593529, 12.10807565367242, 86.83920373296597, 34.082759928077635, 17.765129828258146, 22.99220199409791, 28.91114644242846, 21.450817330092946, 15.262698118396084, 27.734921684669136, 15.246515681537378, 18.571129179425125, 19.248592469238517, 18.07343679093417, 17.97930439410062, 18.08576373751966, 72.81542838833846, 45.892870784455006, 41.820275164323554, 40.54233530780597, 40.35761258840935, 35.761643660683205, 35.76197638758125, 35.76155288766508, 34.87898394044233, 41.15758438414999, 29.58883611383984, 22.642348688208983, 21.416778621432975, 17.885261995695735, 17.307664050594042, 16.473262391970888, 14.938279900833205, 13.564899635548606, 11.907046500072285, 11.907329902488762, 11.907341828126505, 11.906928050534702, 12.848664292017563, 10.181620603145857, 9.837345050820913, 9.670141581686911, 9.605632749364705, 9.60593908311798, 10.652227299470965, 9.053873578776566, 9.166808338566135, 9.202975536908527, 38.20476407920197, 20.715634026661817, 19.70740682143034, 10.089719089349547, 10.063240539310277], \"Term\": [\"notebook\", \"nanodegree\", \"learn\", \"data\", \"day\", \"idea\", \"learning\", \"100daysofcode\", \"video\", \"program\", \"graffiti\", \"live\", \"top\", \"sound\", \"projectjupyter\", \"annotation\", \"betatim\", \"new\", \"machine\", \"google\", \"computer\", \"marketing\", \"free\", \"science\", \"want\", \"amazon\", \"great\", \"work\", \"customer\", \"job\", \"data\", \"100daysofcode\", \"day\", \"nanodegree\", \"program\", \"learning\", \"machine\", \"work\", \"amazon\", \"machinelearning\", \"100daysofswift\", \"unofficial\", \"irvanization\", \"sagemaker\", \"healthcare\", \"datascience\", \"launch\", \"engineer\", \"self\", \"unlearning\", \"relearning\", \"loop\", \"array\", \"high\", \"udacitys\", \"driving\", \"aws\", \"dm\", \"late\", \"nanodeg\", \"new\", \"awesome\", \"service\", \"course\", \"ai\", \"graduate\", \"take\", \"project\", \"look\", \"student\", \"skill\", \"today\", \"career\", \"computer\", \"science\", \"want\", \"hey\", \"need\", \"robotics\", \"lot\", \"people\", \"year\", \"without\", \"programming\", \"favorite\", \"nanodegrees\", \"celebrate\", \"bjarne\", \"interested\", \"anyone\", \"dream\", \"code\", \"invest\", \"father\", \"jumaallan\", \"academic\", \"background\", \"hn\", \"google\", \"girlcoders\", \"language\", \"girlcode\", \"za\", \"free\", \"thing\", \"learn\", \"job\", \"help\", \"build\", \"web\", \"start\", \"scholarship\", \"today\", \"developer\", \"app\", \"look\", \"skill\", \"career\", \"course\", \"notebook\", \"idea\", \"video\", \"live\", \"top\", \"projectjupyter\", \"sound\", \"annotation\", \"betatim\", \"graffiti\", \"marketing\", \"customer\", \"online\", \"product\", \"edx\", \"platform\", \"content\", \"lay\", \"percent\", \"operation\", \"restructure\", \"workforce\", \"udemy\", \"sneak\", \"kotlin\", \"edemkumodzi\", \"discover\", \"breakout\", \"watch\", \"driven\", \"minute\", \"im\", \"great\", \"like\", \"learn\", \"peek\", \"ai\"], \"Total\": [73.0, 108.0, 106.0, 86.0, 84.0, 46.0, 78.0, 74.0, 42.0, 71.0, 41.0, 40.0, 40.0, 36.0, 36.0, 36.0, 35.0, 73.0, 57.0, 40.0, 34.0, 29.0, 37.0, 31.0, 29.0, 43.0, 55.0, 41.0, 22.0, 44.0, 86.38549393855207, 74.58647254861906, 84.77738910344536, 108.26417871001507, 71.66133639523862, 78.81923676968965, 57.26979395576619, 41.977978336759186, 43.53153949653012, 38.267597477574476, 32.61780736590094, 32.617992672231466, 29.529742557941344, 27.42825536298524, 24.85511129136215, 24.766789579137303, 24.035259235661233, 22.46556178772637, 20.20124928506299, 19.424045068805583, 19.423448395125405, 19.423919176795746, 19.423197293336855, 17.667232057896413, 41.9250684247886, 17.019000282057984, 16.23449163991414, 15.620336774003036, 15.401422363760673, 15.15852527347955, 73.7637095709772, 23.324591139460228, 16.636153087481865, 96.95252654391544, 52.998590280387866, 23.7279490311057, 46.37137312445857, 41.352937606674956, 56.776531062324864, 36.357830776150934, 49.25800604125012, 59.11462496200434, 54.36631688488569, 34.557906638602695, 31.532074912041992, 29.782323058159278, 22.503185508948526, 22.540394637909763, 20.834251736957455, 19.2377418945624, 19.109908793625443, 18.412418185496445, 17.27636546236362, 16.831777562218736, 16.06605186620416, 15.766973791582483, 15.503174459316273, 15.143804488813451, 15.24782941265493, 14.325402548300133, 14.206980817989361, 13.608213645910292, 14.915682864521507, 13.067666305712457, 12.86064636227934, 12.617503739850102, 12.61722834220604, 12.617724018466275, 40.041584774426894, 12.405134596930353, 12.195377222248666, 11.703190129799436, 11.703107939099416, 37.7174911062661, 12.510619675829204, 106.75175730289138, 44.17827888850171, 20.17203717645317, 30.00752736612388, 46.39586334049001, 32.66703082820763, 18.436862018713796, 59.11462496200434, 20.07029417284577, 36.48694747597973, 56.776531062324864, 49.25800604125012, 54.36631688488569, 96.95252654391544, 73.1876998861514, 46.256124713977655, 42.17911091561716, 40.89781182431892, 40.75588958168362, 36.11803511568877, 36.118503426030195, 36.11809556803435, 35.235557070475814, 41.64256803244024, 29.945616452132207, 22.998745995279968, 21.775047914544754, 18.24455200623399, 17.66426639076396, 16.828623808641158, 15.32350382540224, 13.920574402782483, 12.262448834000796, 12.262829649912186, 12.263047179066202, 12.262876888967382, 13.248035976001772, 10.544174899638707, 10.19414707508481, 10.026899600778918, 9.96085750139103, 9.961416653799734, 11.062566529383611, 9.409126206312315, 9.526956501287268, 9.56951755262877, 55.902074582071094, 36.14201055999699, 106.75175730289138, 12.076137282364023, 52.998590280387866], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8109, 0.8104, 0.8102, 0.8101, 0.8096, 0.8095, 0.8077, 0.8066, 0.8063, 0.8059, 0.8043, 0.8043, 0.8032, 0.8016, 0.8009, 0.8006, 0.7998, 0.7982, 0.797, 0.7967, 0.7967, 0.7967, 0.7967, 0.7949, 0.7941, 0.794, 0.7931, 0.792, 0.7918, 0.7915, 0.77, 0.7765, 0.7891, 0.515, 0.6006, 0.719, 0.5422, 0.5579, 0.3923, 0.5442, 0.3523, 0.1762, 0.2246, 1.1875, 1.1861, 1.1846, 1.182, 1.1818, 1.1799, 1.1791, 1.1786, 1.1784, 1.1766, 1.1762, 1.1756, 1.175, 1.1748, 1.1742, 1.1739, 1.1728, 1.1722, 1.1711, 1.1705, 1.1704, 1.1695, 1.1693, 1.1693, 1.1693, 1.1689, 1.1688, 1.1683, 1.167, 1.167, 1.14, 1.1654, 0.9917, 0.9387, 1.0711, 0.9318, 0.7251, 0.7775, 1.0092, 0.4413, 0.9232, 0.5228, 0.1164, 0.1955, 0.0916, -0.481, 1.3586, 1.3558, 1.3551, 1.355, 1.3539, 1.3538, 1.3538, 1.3538, 1.3535, 1.352, 1.3517, 1.3481, 1.3471, 1.3438, 1.3433, 1.3423, 1.3382, 1.3378, 1.3343, 1.3343, 1.3342, 1.3342, 1.3331, 1.3287, 1.3281, 1.3275, 1.3274, 1.3273, 1.3259, 1.3252, 1.3251, 1.3246, 0.983, 0.8071, -0.3258, 1.184, -0.2977], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.8909, -4.0382, -3.9104, -3.6659, -4.079, -3.9839, -4.3051, -4.6169, -4.5808, -4.7101, -4.8714, -4.8714, -4.972, -5.0475, -5.1467, -5.1505, -5.1813, -5.2504, -5.3579, -5.3974, -5.3974, -5.3974, -5.3974, -5.494, -4.6306, -5.5323, -5.5804, -5.6201, -5.6344, -5.6506, -4.0897, -5.2346, -5.5599, -4.0714, -4.5898, -5.275, -4.7817, -4.8806, -4.7292, -5.0231, -4.9112, -4.9049, -4.9403, -4.4305, -4.5235, -4.5821, -4.865, -4.8636, -4.9442, -5.0247, -5.0318, -5.0692, -5.1346, -5.1612, -5.2083, -5.2277, -5.2448, -5.2688, -5.2623, -5.3258, -5.3347, -5.3789, -5.2877, -5.4201, -5.4369, -5.4562, -5.4563, -5.4562, -4.3018, -5.4737, -5.4912, -5.5338, -5.5338, -4.3905, -5.4686, -3.4985, -4.4337, -5.0853, -4.8274, -4.5983, -4.8968, -5.2371, -4.6398, -5.2382, -5.0409, -5.0051, -5.0681, -5.0733, -5.0674, -3.509, -3.9706, -4.0636, -4.0946, -4.0992, -4.2201, -4.2201, -4.2201, -4.2451, -4.0795, -4.4095, -4.6771, -4.7328, -4.913, -4.9458, -4.9952, -5.093, -5.1895, -5.3198, -5.3198, -5.3198, -5.3198, -5.2437, -5.4764, -5.5108, -5.5279, -5.5346, -5.5346, -5.4312, -5.5938, -5.5814, -5.5774, -4.154, -4.7661, -4.8159, -5.4854, -5.4881]}, \"token.table\": {\"Topic\": [1, 1, 2, 1, 3, 1, 3, 2, 1, 2, 3, 1, 1, 3, 1, 2, 3, 2, 3, 2, 3, 1, 2, 3, 2, 2, 2, 3, 1, 2, 3, 3, 1, 1, 1, 1, 2, 3, 1, 2, 3, 1, 3, 3, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 2, 1, 2, 3, 3, 2, 2, 1, 1, 2, 2, 3, 2, 1, 1, 3, 2, 3, 1, 1, 3, 3, 1, 2, 1, 2, 1, 1, 3, 3, 1, 1, 2, 2, 1, 2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 1, 2, 1, 3, 3, 1, 3, 2, 1, 1, 2, 2, 1, 1, 1, 2, 3, 3, 1, 2, 1, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 1, 3, 2, 3, 1, 2, 2, 1, 3, 2, 2], \"Freq\": [0.9921370118658345, 0.9810591999955582, 0.951059753768899, 0.811342335192492, 0.18868426399825394, 0.9877895543627054, 0.9967302936055448, 0.9772849281405537, 0.411105916982364, 0.5207341615109944, 0.0822211833964728, 0.9782117595293112, 0.9432105312568887, 0.04287320596622221, 0.9855559604134682, 0.9510805126557517, 0.9933147907948591, 0.9905040712246597, 1.0038732790265879, 0.766474348898376, 0.23327480183863616, 0.5518122565396786, 0.3310873539238071, 0.1103624513079357, 0.9675437788153185, 0.9553054014482585, 0.983855890218203, 0.978888390730457, 0.7426314977710974, 0.18565787444277435, 0.07220028450552336, 1.0000545249171537, 0.9955375153746729, 0.9690396053680199, 0.9908302306585923, 0.2491244003172002, 0.7473732009516005, 1.0039296314201365, 0.9602865941382606, 0.9854310482543008, 0.9565181508525368, 0.9988835841269704, 0.997317256395304, 0.9623949064133633, 0.9792766460894506, 0.9948218523392446, 0.9958887306754497, 0.05302579629077542, 0.9544643332339575, 0.9399146624125223, 0.9673413783812871, 0.024974036508132007, 0.9739874238171483, 0.9271766376082282, 0.08428878523711165, 0.9845694426928794, 0.16099581397085536, 0.16099581397085536, 0.6797601034325004, 0.9655961592230197, 0.04957357510560711, 0.892324351900928, 0.09914715021121422, 0.97763936538014, 0.9622333563226056, 0.9510431502890518, 0.9944629016035954, 0.9404862837131928, 0.9837465775653783, 1.0056529182233453, 0.9820607119448496, 0.22635558133077707, 0.769608976524642, 0.9330790740966456, 0.9809550447276438, 0.9839794031223381, 0.9739360200454463, 0.998533020371633, 1.0057056264288664, 0.814974874400907, 0.18735054583928895, 0.9896061316594137, 0.41502948418155877, 0.5810412778541822, 1.0024986220808105, 0.6516777145011603, 0.33464531285194715, 0.9781754046164809, 0.9876419022635085, 0.9952890706054474, 0.9930072046531979, 1.001816077086098, 0.9446878443061993, 0.9895421704539494, 0.9975598696340489, 0.9513556753679677, 0.9760255023662764, 0.9489761348382884, 0.04067040577878379, 0.9974353629579371, 0.9644066034854942, 0.9785669655849726, 0.1656158714691657, 0.8280793573458285, 0.9942485966410208, 0.978597355426015, 0.9507610474829393, 0.9865958886712904, 0.990771363911062, 0.9505829043222519, 0.7738265248376149, 0.2176387101105792, 0.9967319618769213, 0.978199113436949, 0.9785496071877436, 0.9599576818265283, 0.9843863433048251, 0.1627174948185292, 0.813587474092646, 0.9831259150079339, 0.9900377802271964, 0.9617608058704059, 0.6293393194608746, 0.3654228306547014, 0.9483909452547726, 0.9967190383102975, 0.3367309400676115, 0.6428499764927128, 0.7701229529448911, 0.22003512941282605, 0.7547760103213174, 0.08626011546529341, 0.15095520206426347, 0.9591851012131931, 0.5244049170560603, 0.47365605411515127, 0.9814532429682672, 0.977935195825664, 0.023852077946967414, 0.9812775284992373, 0.9781690648212824, 0.9810536264925469, 0.9957535635121497, 0.9737319665550753, 0.9943443025434083, 0.36641197675836706, 0.6250557250583909, 0.9840032637092749, 1.0005246003765154, 0.9785631959492405, 0.9776010852381515, 0.9399212634149624], \"Term\": [\"100daysofcode\", \"100daysofswift\", \"academic\", \"ai\", \"ai\", \"amazon\", \"annotation\", \"anyone\", \"app\", \"app\", \"app\", \"array\", \"awesome\", \"awesome\", \"aws\", \"background\", \"betatim\", \"bjarne\", \"breakout\", \"build\", \"build\", \"career\", \"career\", \"career\", \"celebrate\", \"code\", \"computer\", \"content\", \"course\", \"course\", \"course\", \"customer\", \"data\", \"datascience\", \"day\", \"developer\", \"developer\", \"discover\", \"dm\", \"dream\", \"driven\", \"driving\", \"edemkumodzi\", \"edx\", \"engineer\", \"father\", \"favorite\", \"free\", \"free\", \"girlcode\", \"girlcoders\", \"google\", \"google\", \"graduate\", \"graduate\", \"graffiti\", \"great\", \"great\", \"great\", \"healthcare\", \"help\", \"help\", \"help\", \"hey\", \"high\", \"hn\", \"idea\", \"im\", \"interested\", \"invest\", \"irvanization\", \"job\", \"job\", \"jumaallan\", \"kotlin\", \"language\", \"late\", \"launch\", \"lay\", \"learn\", \"learn\", \"learning\", \"like\", \"like\", \"live\", \"look\", \"look\", \"loop\", \"lot\", \"machine\", \"machinelearning\", \"marketing\", \"minute\", \"nanodeg\", \"nanodegree\", \"nanodegrees\", \"need\", \"new\", \"new\", \"notebook\", \"online\", \"operation\", \"peek\", \"peek\", \"people\", \"percent\", \"platform\", \"product\", \"program\", \"programming\", \"project\", \"project\", \"projectjupyter\", \"relearning\", \"restructure\", \"robotics\", \"sagemaker\", \"scholarship\", \"scholarship\", \"science\", \"self\", \"service\", \"skill\", \"skill\", \"sneak\", \"sound\", \"start\", \"start\", \"student\", \"student\", \"take\", \"take\", \"take\", \"thing\", \"today\", \"today\", \"top\", \"udacitys\", \"udacitys\", \"udemy\", \"unlearning\", \"unofficial\", \"video\", \"want\", \"watch\", \"web\", \"web\", \"without\", \"work\", \"workforce\", \"year\", \"za\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2301621963515820242389832568\", ldavis_el2301621963515820242389832568_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2301621963515820242389832568\", ldavis_el2301621963515820242389832568_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2301621963515820242389832568\", ldavis_el2301621963515820242389832568_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
       "topic                                                    \n",
       "2     -372.142456 -195.243271       1        1  44.251853\n",
       "0     -437.769562 -443.703552       2        1  30.176354\n",
       "1     -620.127258 -262.638367       3        1  25.571793, topic_info=     Category        Freq            Term       Total  loglift  logprob\n",
       "term                                                                   \n",
       "1360  Default   73.000000        notebook   73.000000  30.0000  30.0000\n",
       "1310  Default  108.000000      nanodegree  108.000000  29.0000  29.0000\n",
       "1148  Default  106.000000           learn  106.000000  28.0000  28.0000\n",
       "489   Default   86.000000            data   86.000000  27.0000  27.0000\n",
       "496   Default   84.000000             day   84.000000  26.0000  26.0000\n",
       "932   Default   46.000000            idea   46.000000  25.0000  25.0000\n",
       "1149  Default   78.000000        learning   78.000000  24.0000  24.0000\n",
       "8     Default   74.000000   100daysofcode   74.000000  23.0000  23.0000\n",
       "2050  Default   42.000000           video   42.000000  22.0000  22.0000\n",
       "1514  Default   71.000000         program   71.000000  21.0000  21.0000\n",
       "825   Default   41.000000        graffiti   41.000000  20.0000  20.0000\n",
       "1176  Default   40.000000            live   40.000000  19.0000  19.0000\n",
       "1948  Default   40.000000             top   40.000000  18.0000  18.0000\n",
       "1783  Default   36.000000           sound   36.000000  17.0000  17.0000\n",
       "1519  Default   36.000000  projectjupyter   36.000000  16.0000  16.0000\n",
       "176   Default   36.000000      annotation   36.000000  15.0000  15.0000\n",
       "267   Default   35.000000         betatim   35.000000  14.0000  14.0000\n",
       "1336  Default   73.000000             new   73.000000  13.0000  13.0000\n",
       "1204  Default   57.000000         machine   57.000000  12.0000  12.0000\n",
       "814   Default   40.000000          google   40.000000  11.0000  11.0000\n",
       "415   Default   34.000000        computer   34.000000  10.0000  10.0000\n",
       "1218  Default   29.000000       marketing   29.000000   9.0000   9.0000\n",
       "753   Default   37.000000            free   37.000000   8.0000   8.0000\n",
       "1691  Default   31.000000         science   31.000000   7.0000   7.0000\n",
       "2081  Default   29.000000            want   29.000000   6.0000   6.0000\n",
       "158   Default   43.000000          amazon   43.000000   5.0000   5.0000\n",
       "827   Default   55.000000           great   55.000000   4.0000   4.0000\n",
       "2137  Default   41.000000            work   41.000000   3.0000   3.0000\n",
       "474   Default   22.000000        customer   22.000000   2.0000   2.0000\n",
       "1051  Default   44.000000             job   44.000000   1.0000   1.0000\n",
       "...       ...         ...             ...         ...      ...      ...\n",
       "176    Topic3   35.761553      annotation   36.118096   1.3538  -4.2201\n",
       "267    Topic3   34.878984         betatim   35.235557   1.3535  -4.2451\n",
       "825    Topic3   41.157584        graffiti   41.642568   1.3520  -4.0795\n",
       "1218   Topic3   29.588836       marketing   29.945616   1.3517  -4.4095\n",
       "474    Topic3   22.642349        customer   22.998746   1.3481  -4.6771\n",
       "1388   Topic3   21.416779          online   21.775048   1.3471  -4.7328\n",
       "1508   Topic3   17.885262         product   18.244552   1.3438  -4.9130\n",
       "599    Topic3   17.307664             edx   17.664266   1.3433  -4.9458\n",
       "1464   Topic3   16.473262        platform   16.828624   1.3423  -4.9952\n",
       "425    Topic3   14.938280         content   15.323504   1.3382  -5.0930\n",
       "1142   Topic3   13.564900             lay   13.920574   1.3378  -5.1895\n",
       "1440   Topic3   11.907047         percent   12.262449   1.3343  -5.3198\n",
       "1393   Topic3   11.907330       operation   12.262830   1.3343  -5.3198\n",
       "1633   Topic3   11.907342     restructure   12.263047   1.3342  -5.3198\n",
       "2138   Topic3   11.906928       workforce   12.262877   1.3342  -5.3198\n",
       "1988   Topic3   12.848664           udemy   13.248036   1.3331  -5.2437\n",
       "1760   Topic3   10.181621           sneak   10.544175   1.3287  -5.4764\n",
       "1103   Topic3    9.837345          kotlin   10.194147   1.3281  -5.5108\n",
       "592    Topic3    9.670142     edemkumodzi   10.026900   1.3275  -5.5279\n",
       "539    Topic3    9.605633        discover    9.960858   1.3274  -5.5346\n",
       "304    Topic3    9.605939        breakout    9.961417   1.3273  -5.5346\n",
       "2084   Topic3   10.652227           watch   11.062567   1.3259  -5.4312\n",
       "560    Topic3    9.053874          driven    9.409126   1.3252  -5.5938\n",
       "1262   Topic3    9.166808          minute    9.526957   1.3251  -5.5814\n",
       "946    Topic3    9.202976              im    9.569518   1.3246  -5.5774\n",
       "827    Topic3   38.204764           great   55.902075   0.9830  -4.1540\n",
       "1167   Topic3   20.715634            like   36.142011   0.8071  -4.7661\n",
       "1148   Topic3   19.707407           learn  106.751757  -0.3258  -4.8159\n",
       "1437   Topic3   10.089719            peek   12.076137   1.1840  -5.4854\n",
       "133    Topic3   10.063241              ai   52.998590  -0.2977  -5.4881\n",
       "\n",
       "[156 rows x 6 columns], token_table=      Topic      Freq            Term\n",
       "term                                 \n",
       "8         1  0.992137   100daysofcode\n",
       "10        1  0.981059  100daysofswift\n",
       "98        2  0.951060        academic\n",
       "133       1  0.811342              ai\n",
       "133       3  0.188684              ai\n",
       "158       1  0.987790          amazon\n",
       "176       3  0.996730      annotation\n",
       "181       2  0.977285          anyone\n",
       "187       1  0.411106             app\n",
       "187       2  0.520734             app\n",
       "187       3  0.082221             app\n",
       "202       1  0.978212           array\n",
       "229       1  0.943211         awesome\n",
       "229       3  0.042873         awesome\n",
       "230       1  0.985556             aws\n",
       "241       2  0.951081      background\n",
       "267       3  0.993315         betatim\n",
       "280       2  0.990504          bjarne\n",
       "304       3  1.003873        breakout\n",
       "317       2  0.766474           build\n",
       "317       3  0.233275           build\n",
       "336       1  0.551812          career\n",
       "336       2  0.331087          career\n",
       "336       3  0.110362          career\n",
       "348       2  0.967544       celebrate\n",
       "396       2  0.955305            code\n",
       "415       2  0.983856        computer\n",
       "425       3  0.978888         content\n",
       "440       1  0.742631          course\n",
       "440       2  0.185658          course\n",
       "...     ...       ...             ...\n",
       "1751      1  0.629339           skill\n",
       "1751      2  0.365423           skill\n",
       "1760      3  0.948391           sneak\n",
       "1783      3  0.996719           sound\n",
       "1812      1  0.336731           start\n",
       "1812      2  0.642850           start\n",
       "1837      1  0.770123         student\n",
       "1837      3  0.220035         student\n",
       "1867      1  0.754776            take\n",
       "1867      2  0.086260            take\n",
       "1867      3  0.150955            take\n",
       "1922      2  0.959185           thing\n",
       "1943      1  0.524405           today\n",
       "1943      2  0.473656           today\n",
       "1948      3  0.981453             top\n",
       "1987      1  0.977935        udacitys\n",
       "1987      2  0.023852        udacitys\n",
       "1988      3  0.981278           udemy\n",
       "2004      1  0.978169      unlearning\n",
       "2006      1  0.981054      unofficial\n",
       "2050      3  0.995754           video\n",
       "2081      2  0.973732            want\n",
       "2084      3  0.994344           watch\n",
       "2089      1  0.366412             web\n",
       "2089      2  0.625056             web\n",
       "2118      2  0.984003         without\n",
       "2137      1  1.000525            work\n",
       "2138      3  0.978563       workforce\n",
       "2182      2  0.977601            year\n",
       "2205      2  0.939921              za\n",
       "\n",
       "[152 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "visualization_panel = pyLDAvis.sklearn.prepare(lda_udacity_corpus, bow_udacity_corpus, bow_vectorizer_udacity, mds='tsne')\n",
    "visualization_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Evaluation Based on Log-Likelihood, Perplexity and Coherence Scores ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "udacity_corpus_tokenized = [tokenize_text(normalized_udacity[doc_id]) for doc_id in range(len(normalized_udacity))]\n",
    "udacity_dictionary = Dictionary(udacity_corpus_tokenized)\n",
    "udacity_corpus_bow = [udacity_dictionary.doc2bow(doc) for doc in udacity_corpus_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence score for the model:  -4.3187\n",
      "Coherence score by topic:  [-3.038  -6.3236 -4.2539 -3.6592]\n"
     ]
    }
   ],
   "source": [
    "cm = CoherenceModel(topics=topic_words, \n",
    "                    corpus = udacity_corpus_bow , \n",
    "                    dictionary = udacity_dictionary, coherence='u_mass')\n",
    "print(\"Coherence score for the model: \", np.round(cm.get_coherence(),4))  # get coherence value\n",
    "print(\"Coherence score by topic: \", np.round(cm.get_coherence_per_topic(),4)) #coherence score by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood (higher values are better):  -64993.95479878974\n",
      "Perplexity (lower values are better):  925.8235226912636\n"
     ]
    }
   ],
   "source": [
    "print(\"Log-Likelihood (higher values are better): \", lda_udacity_corpus.score(bow_udacity_corpus))\n",
    "print(\"Perplexity (lower values are better): \", lda_udacity_corpus.perplexity(bow_udacity_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_highest_loglikelihood(lowest, highest):\n",
    "    candidate = []\n",
    "    for i in range(lowest,highest+1):\n",
    "        candidate.append(i)\n",
    "    no_keywords = 10\n",
    "    res = []\n",
    "    for i in range(lowest,highest+1):\n",
    "        no_topics = i    \n",
    "        lda_udacity_corpus = LatentDirichletAllocation(n_components=no_topics, max_iter=100,random_state = 42).fit(bow_udacity_corpus)\n",
    "        res.append(lda_udacity_corpus.score(bow_udacity_corpus))\n",
    "    idx = res.index(max(res))\n",
    "    return candidate[idx]\n",
    "def select_lowest_perplexity(lowest, highest):\n",
    "    candidate = []\n",
    "    for i in range(lowest,highest+1):\n",
    "        candidate.append(i)\n",
    "    no_keywords = 10\n",
    "    res = []\n",
    "    for i in range(lowest,highest+1):\n",
    "        no_topics = i    \n",
    "        lda_udacity_corpus = LatentDirichletAllocation(n_components=no_topics, max_iter=100,random_state = 42).fit(bow_udacity_corpus)\n",
    "        res.append(lda_udacity_corpus.perplexity(bow_udacity_corpus))\n",
    "    idx = res.index(min(res))\n",
    "    return candidate[idx]\n",
    "def select_highest_coherence_score(lowest, highest):\n",
    "    candidate = []\n",
    "    for i in range(lowest,highest+1):\n",
    "        candidate.append(i)\n",
    "    no_keywords = 10\n",
    "    res = []\n",
    "    for i in range(lowest,highest+1):\n",
    "        no_topics = i    \n",
    "        lda_udacity_corpus = LatentDirichletAllocation(n_components=no_topics, max_iter=100,random_state = 42).fit(bow_udacity_corpus)\n",
    "        topic_words = get_topic_words(vectorizer = bow_vectorizer_udacity, \n",
    "                              lda_model = lda_udacity_corpus, \n",
    "                              n_words = no_keywords)\n",
    "        cm = CoherenceModel(topics=topic_words, corpus = udacity_corpus_bow , dictionary = udacity_dictionary, coherence='u_mass')\n",
    "        res.append(np.round(cm.get_coherence(),4))\n",
    "    idx = res.index(max(res))\n",
    "    return candidate[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_highest_loglikelihood(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_lowest_perplexity(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_highest_coherence_score(2, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
